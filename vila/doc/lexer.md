# The Lexer

The lexer will take in the code (series of characters) and groups it into a series of chunks (smallest sequences that still represent something) called *tokens*. The tokens are the stuff that make up the grammar.

## Token

```nimble
[mut] [hello] [=] ["Hello"] [;]
```

Each blob of characters is called a *lexeme*. They are small, raw substrings of the code. However, when we group character sequences into lexemes, we may also find other useful information that we would want to store. So we group the lexeme and those information into a *token*.

Here are some of those useful information:

### Token type

If the lexer recognizes a lexeme, it also remembers which kind of lexeme it is. These kinds are called token type. There are many different types, each representing a different keyword, operator, punctuation, and literal type.

This is all the token type that NIMBLE can recognize:

```cpp
enum TokenType
{
    // single character tokens
    LEFT_PAREN, RIGHT_PAREN, LEFT_BRACE, RIGHT_BRACE, LEFT_BRACKET, RIGHT_BRACKET,
    COMMA, DOT, MINUS, PLUS, SEMICOLON, SLASH, STAR, PERCENT, COLON,

    // 1 or 2 characters tokens
    BANG, BANG_EQUAL,
    EQUAL, EQUAL_EQUAL,
    GREATER, GREATER_EQUAL,
    LESS, LESS_EQUAL,
    STAR_STAR,

    // literals tokens
    IDENTIFIER, STRING, NUMBER,

    // keywords
    AND, BREAK, CLASS, ELSE, FALSE, FUN, FOR, IF, NIL, OR,
    PRINT, RETURN, SUPER, THIS, TRUE, MUT, WHILE,

    // end of file
    TOKEN_EOF
};
```

### Literal value

There are lexemes for literal values (numbers, strings, etc). Since the lexer has to scan each character in the literal to identify it, it can also convert that textual representation of a value to the runtime object that will be used by the interpreter later.

### Location information

Location tracking allows us to pass those location data to the error handler. 

## Lexing

The core of the lexer is a loop. It loops through each character of the code, it figures out what lexeme the current character belongs to, consumes it and any following characters that are a part of that lexeme. It then creates a token at the end of the lexeme.

The lexer will keep looping back and do it again for the next character. The rules that determine how a particular group of characters is converted into lexemes is called *lexical grammar*.

## Lexer information

The lexer stores information of the source code as a string. It also has a list to store the tokens that will be generated by the lexer.

The lexer's main function is called `scan_tokens()`. This function runs a loop through the entire source code string and analyzes each of the character until it runs out of character, then it appends an end of file token to the end.

```cpp
std::vector<Token> Lexer::scan_tokens()
{
    while (!is_at_end())
    {
        start = current;
        scan_token();
    }

    tokens.emplace_back(TokenType::TOKEN_EOF, "", nullptr, line);
    return tokens;
}
```

The lexer also keeps track of where the lexer is currently through 3 fields: `start`, `current`, and `line`.

The `start` field points to the first character in the lexeme being scanned. The `current` field points to the current character being analyzed.

The lexer utilizes a `switch` condition to recognize the characters. For invalid characters, it still gets consumed by the `advance()` function for evaluation. This is useful for identifying identifiers and numbers. It it doesn't match any of those cases, then it throughs an "Unexpected character" error.

The lexer doesn't stop scanning even when there's an error. This is because there may be other errors later in the program and we want to detect those and notify the user about it.

The `peek()` function allows us to look at the next unconsumed character without actually consuming it, this is very useful and is used for stuff like comments. Comments needs to be ignored so if the lexer detects a `//`, it will consume everything after that till the end of the line, but it won't do anything about it, it will just ignore it.

Strings are wrapped around double quotes so that's not super hard to identify. Numbers are numbers, so using the `std::isdigit()` function allows us to recognize that. We do need to look out for a decimal point though, so we have the `peek_next()` function, which allows us peek pass the character `peek()` is currently pointing to. If `peek()` is on the decimal point, we can use `peek_next()` to check if the next character is a digit or not. If not then we won't continue evaluating the number.

For the identifiers, this is usually a keyword in the language like `true` or `nil` or `for`, but it also represents the name of functions, classes, etc. To evaluate the identifiers, there's a *keyword* map, which allows us to check if an identifier matches a keyword or not, and get the token type of that keyword. The `identifier()` function will evaluate the entire word instead of a single character. If it has found a match in the keyword map, then it will return the corresponding token type of the keyword if there is a match, if not then it will return an identifier token.
